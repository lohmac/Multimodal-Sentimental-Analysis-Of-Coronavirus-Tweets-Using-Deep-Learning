{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb258aa8de97456483ae64f2045d8697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580cbab182e2485a93a36629df420115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5a0a725aee45f588e332627010aa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72508585298d4d4da594f08431ed7f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/63.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Importing of Packages\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFBertModel, logging\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "bert = TFAlbertModel.from_pretrained('albert-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Datset\n",
    "dat = pd.read_csv('fin_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation Of Data Pipelines\n",
    "#https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "\n",
    "class preparation():\n",
    "    def __init__(self,df,tokenizer,bert,max_len_tweet,max_len_text_data,tweet=True,tweet_text=True,image=True):\n",
    "        self.df=df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert = bert\n",
    "        self.max_len_tweet=max_len_tweet\n",
    "        self.max_len_text_data=max_len_text_data\n",
    "        self.tweet=tweet\n",
    "        self.tweet_text=tweet_text\n",
    "        self.image=image\n",
    "        self.tokenizer=tokenizer\n",
    "        self.bert=bert\n",
    "        \n",
    "        \n",
    "    #TOKENIZATION OF TEXT    \n",
    "    def tokenize(self,sentences,max_len):\n",
    "        \n",
    "        input_ids=[]\n",
    "        attention_masks=[]\n",
    "        for sent in sentences:\n",
    "            bert_inp=self.tokenizer.encode_plus(sent,max_length=max_len,add_special_tokens = True,pad_to_max_length = True,return_attention_mask = True,truncation = True)\n",
    "            input_ids.append(bert_inp['input_ids'])\n",
    "            attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "        input_ids=np.asarray(input_ids)\n",
    "        attention_masks=np.array(attention_masks)\n",
    "        return input_ids,attention_masks\n",
    "    \n",
    "    \n",
    "    def prep_txt(self,input_ids, masks, input_ids2, masks2, path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2,'images': image}, labels\n",
    "\n",
    "\n",
    "    def prep_image(self,path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'images1': image}, labels\n",
    "\n",
    "    def prep_tweet(self,input_ids, masks, labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "    \n",
    "    def prep_txt_imtxt_image(self,input_ids, masks, input_ids2, masks2,labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2}, labels\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def prep_data_pipeline(self):\n",
    "        sentences=self.df['tweet']\n",
    "        sentences1=self.df['text_data']\n",
    "        input_ids,attention_masks=self.tokenize(sentences,self.max_len_tweet)\n",
    "        input_ids1,attention_masks1=self.tokenize(sentences1,self.max_len_text_data)\n",
    "        paths =[img for i,img in enumerate(self.df['Path'])]\n",
    "        labels=self.df['Target'].to_numpy()#.reshape((-1,1))\n",
    "        if self.tweet:\n",
    "            if self.tweet_text:\n",
    "                if self.image:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,paths,labels)).map(self.prep_txt).batch(5)\n",
    "                    \n",
    "                else:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,labels)).map(self.prep_txt_imtxt_image).batch(5)\n",
    "                   \n",
    "            \n",
    "            elif self.tweet_text==False:\n",
    "                if self.image==False:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks,labels)).map(self.prep_tweet).batch(5)\n",
    "                    \n",
    "                \n",
    "                \n",
    "        elif self.tweet==False:\n",
    "            if self.tweet_text==False:\n",
    "                if self.image:\n",
    "                    dataset=tf.data.Dataset.from_tensor_slices((paths,labels)).map(self.prep_image).batch(5)\n",
    "                    \n",
    "                    \n",
    "        return dataset    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_1,test_1=train_test_split(dat, test_size=.25, random_state=42)\n",
    "train=preparation(df=train_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=False,image=False).prep_data_pipeline()\n",
    "test=preparation(df=test_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=False,image=False).prep_data_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.BatchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.Dense1 = tf.keras.layers.Dense(115, activation='relu', kernel_regularizer=l2(0.01))\n",
    "        self.Dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.Dense2 = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.BatchNormalization(inputs)\n",
    "        x = self.Dense1(x)\n",
    "        x = self.Dropout(x)\n",
    "        x = self.Dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rob(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Rob, self).__init__()\n",
    "        #self.Flat=tf.keras.layers.Flatten()\n",
    "        self.GlobalMaxPool1D = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.bert=  TFAlbertModel.from_pretrained('albert-base-v2')\n",
    "        self.block = MLPBlock()\n",
    "        self.bert.trainable=False\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        text_embeddings = bert(inputs[0], attention_mask=inputs[1])[0] #We take the first value from tuple which is the pooled_output which is the embedding hence [0]\n",
    "        #x = self.Flat(x) Can use GlobalMaxPool1D or Flatten but when used Flatten caused overfitting issues\n",
    "        x = self.GlobalMaxPool1D(text_embeddings)\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(tweet,img,tweet_text,tweet_txt_img):\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    checkpoint_filepath = r'C:\\Users\\UWAMAHIRWE\\Desktop\\Thesis\\crypto_data\\model_wt_tweet_albert.ckpt'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "    early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=4, verbose=1)\n",
    "    seq_len=250\n",
    "    seq_len2=245\n",
    "    if img:\n",
    "        ins = tf.keras.layers.Input(shape=(200, 200, 3),name='images1')\n",
    "        outs = Images()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_txt_img:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        image_inputs=tf.keras.layers.Input(shape=(200,200,3),name=\"images\")\n",
    "        ins=[input_ids, mask,input_ids2, mask2,image_inputs]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()    \n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_text:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        ins=[input_ids, mask,input_ids2, mask2]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "        \n",
    "    elif tweet:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        ins=[input_ids, mask]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    \n",
    "    return history,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1a297e63a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1a297e63a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rob (Rob)                       (None, 1)            11775207    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 11,775,207\n",
      "Trainable params: 90,087\n",
      "Non-trainable params: 11,685,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "163/163 [==============================] - ETA: 0s - loss: 3.7406 - accuracy: 0.5970WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "163/163 [==============================] - 791s 5s/step - loss: 3.7338 - accuracy: 0.5971 - val_loss: 0.9913 - val_accuracy: 0.6949\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 720s 4s/step - loss: 0.9399 - accuracy: 0.6922 - val_loss: 0.8221 - val_accuracy: 0.7059\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 718s 4s/step - loss: 0.8554 - accuracy: 0.6416 - val_loss: 0.9887 - val_accuracy: 0.6765\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 717s 4s/step - loss: 0.9219 - accuracy: 0.6561 - val_loss: 0.8374 - val_accuracy: 0.6985\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 717s 4s/step - loss: 0.8157 - accuracy: 0.6770 - val_loss: 0.7459 - val_accuracy: 0.7132\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 725s 4s/step - loss: 0.7829 - accuracy: 0.6734 - val_loss: 0.7291 - val_accuracy: 0.7096\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 724s 4s/step - loss: 0.7701 - accuracy: 0.7046 - val_loss: 0.7686 - val_accuracy: 0.6949\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 720s 4s/step - loss: 0.7395 - accuracy: 0.7169 - val_loss: 0.7202 - val_accuracy: 0.6581\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 720s 4s/step - loss: 0.6915 - accuracy: 0.7019 - val_loss: 0.7147 - val_accuracy: 0.6691\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 716s 4s/step - loss: 0.6961 - accuracy: 0.7000 - val_loss: 0.7301 - val_accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "model=run_model(tweet=True,img=False,tweet_text=False,tweet_txt_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=plt.plot(model[0].history['accuracy'],linestyle='-', marker='s', color='r')\n",
    "y=plt.plot(model[0].history['val_accuracy'],linestyle='-', marker='s', color='b')\n",
    "def plot(train,test):\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.xlim(1, 10)\n",
    "    plt.ylim(0.1,1 )\n",
    "    plt.grid()\n",
    "    return plt.show()\n",
    "plot(x,y)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "z=model[1].predict(test)\n",
    "ypred=np.where(z<=0.49,0,1)\n",
    "ytest=[k for i,j in test for k in j.numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion_mat(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    labels = [\"Negative\",\"Positive\"]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "    disp.plot(cmap=plt.cm.Blues,values_format='d')\n",
    "    return plt.show()\n",
    "\n",
    "confusion_mat(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7835051546391752\n",
      "Recall: 0.510\n",
      "Accuracy: 0.654\n",
      "F1 Score: 0.618\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {}\".format(precision_score(ytest, ypred)))\n",
    "print('Recall: %.3f' % recall_score(ytest, ypred))\n",
    "print('Accuracy: %.3f' % accuracy_score(ytest, ypred))\n",
    "print('F1 Score: %.3f' % f1_score(ytest, ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.58      0.83      0.68       123\n",
      "    Positive       0.78      0.51      0.62       149\n",
      "\n",
      "    accuracy                           0.65       272\n",
      "   macro avg       0.68      0.67      0.65       272\n",
      "weighted avg       0.69      0.65      0.65       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print(classification_report(ytest, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UWAMAH~1\\AppData\\Local\\Temp/ipykernel_20768/758176997.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_1['Pred Target']=ypred\n"
     ]
    }
   ],
   "source": [
    "ypred=ypred.flatten()\n",
    "test_1['Pred Target']=ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.to_csv(\"Predicted_Tweet_Albert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
