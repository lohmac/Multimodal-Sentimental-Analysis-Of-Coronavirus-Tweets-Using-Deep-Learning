{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Importing of Packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFBertModel, logging\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "bert = TFAlbertModel.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "dat = pd.read_csv('fin_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation Of Data Pipelines\n",
    "#https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "\n",
    "\n",
    "class preparation():\n",
    "    def __init__(self,df,tokenizer,bert,max_len_tweet,max_len_text_data,tweet=True,tweet_text=True,image=True):\n",
    "        self.df=df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert = bert\n",
    "        self.max_len_tweet=max_len_tweet\n",
    "        self.max_len_text_data=max_len_text_data\n",
    "        self.tweet=tweet\n",
    "        self.tweet_text=tweet_text\n",
    "        self.image=image\n",
    "        self.tokenizer=tokenizer\n",
    "        self.bert=bert\n",
    "        \n",
    "        \n",
    "        \n",
    "    def tokenize(self,sentences,max_len):\n",
    "        \n",
    "        input_ids=[]\n",
    "        attention_masks=[]\n",
    "        for sent in sentences:\n",
    "            bert_inp=self.tokenizer.encode_plus(sent,max_length=max_len,add_special_tokens = True,pad_to_max_length = True,return_attention_mask = True,truncation = True)\n",
    "            input_ids.append(bert_inp['input_ids'])\n",
    "            attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "        input_ids=np.asarray(input_ids)\n",
    "        attention_masks=np.array(attention_masks)\n",
    "        return input_ids,attention_masks\n",
    "    \n",
    "    \n",
    "    def prep_txt(self,input_ids, masks, input_ids2, masks2, path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2,'images': image}, labels\n",
    "\n",
    "\n",
    "    def prep_image(self,path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'images1': image}, labels\n",
    "\n",
    "    def prep_tweet(self,input_ids, masks, labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "    \n",
    "    def prep_txt_imtxt_image(self,input_ids, masks, input_ids2, masks2,labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2}, labels\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def prep_data_pipeline(self):\n",
    "        sentences=self.df['tweet']\n",
    "        sentences1=self.df['text_data']\n",
    "        input_ids,attention_masks=self.tokenize(sentences,self.max_len_tweet)\n",
    "        input_ids1,attention_masks1=self.tokenize(sentences1,self.max_len_text_data)\n",
    "        paths =[img for i,img in enumerate(self.df['Path'])]\n",
    "        labels=self.df['Target'].to_numpy()#.reshape((-1,1))\n",
    "        if self.tweet:\n",
    "            if self.tweet_text:\n",
    "                if self.image:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,paths,labels)).map(self.prep_txt).batch(5)\n",
    "                    \n",
    "                else:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,labels)).map(self.prep_txt_imtxt_image).batch(5)\n",
    "                    \n",
    "            \n",
    "            elif self.tweet_text==False:\n",
    "                if self.image==False:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks,labels)).map(self.prep_tweet).batch(5)\n",
    "                    \n",
    "                \n",
    "                \n",
    "        elif self.tweet==False:\n",
    "            if self.tweet_text==False:\n",
    "                if self.image:\n",
    "                    dataset=tf.data.Dataset.from_tensor_slices((paths,labels)).map(self.prep_image).batch(5)\n",
    "                        \n",
    "                    \n",
    "        return dataset  \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_1,test_1=train_test_split(dat, test_size=.25, random_state=42)\n",
    "train=preparation(df=train_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=True,image=True).prep_data_pipeline()\n",
    "test=preparation(df=test_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=True,image=True).prep_data_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.BatchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.Dense1 = tf.keras.layers.Dense(115, activation='relu', kernel_regularizer=l2(0.01))\n",
    "        self.Dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.Dense2 = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.BatchNormalization(inputs)\n",
    "        x = self.Dense1(x)\n",
    "        x = self.Dropout(x)\n",
    "        x = self.Dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rob(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Rob, self).__init__()\n",
    "        self.GlobalMaxPool1D = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.GlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.InceptionResNetV2=tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(200,200,3), pooling=False, classes=2)\n",
    "        self.bert=TFAlbertModel.from_pretrained('albert-base-v2')\n",
    "        #self.Flat=tf.keras.layers.Flatten()\n",
    "        self.block = MLPBlock()\n",
    "        self.InceptionResNetV2.trainable=False\n",
    "        self.bert.trainable=False\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_ids_c = tf.keras.layers.concatenate([inputs[0],inputs[2]])\n",
    "        mask_c =  tf.keras.layers.concatenate([inputs[1],inputs[3]])\n",
    "        text_embeddings = bert(input_ids_c, attention_mask=mask_c)[0] #We take the first value from tuple which is the pooled_output which is the embedding hence [0]\n",
    "        text_feat = self.GlobalMaxPool1D(text_embeddings)\n",
    "        image_embeddings = self.InceptionResNetV2(inputs[4])\n",
    "        #self.Flat=tf.keras.layers.Flatten() Can use GlobalAveragePooling2D or Flatten but when used Flatten caused overfitting issues\n",
    "        #https://stackoverflow.com/questions/49295311/what-is-the-difference-between-flatten-and-globalaveragepooling2d-in-keras#:~:text=Flatten%20accepts%20as%20input%20tensor,H*W*n_channels)%20.&text=GlobalAveragePooling2D%20accepts%20as%20input%204D%20tensor.\n",
    "        image_feat = self.GlobalAveragePooling2D(image_embeddings)\n",
    "        x = tf.keras.layers.concatenate([text_feat, image_feat]) #Combining text and image vectors(FUSION) into a single vector\n",
    "        x =self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(tweet,img,tweet_text,tweet_txt_img):\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    checkpoint_filepath = r'C:\\Users\\UWAMAHIRWE\\Desktop\\Thesis\\crypto_data\\model_wt_full_albert_inc.ckpt'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "    early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=4, verbose=1)\n",
    "    seq_len=250\n",
    "    seq_len2=245\n",
    "    if img:\n",
    "        ins = tf.keras.layers.Input(shape=(200, 200, 3),name='images1')\n",
    "        outs = Images()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_txt_img:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        image_inputs=tf.keras.layers.Input(shape=(200,200,3),name=\"images\")\n",
    "        ins=[input_ids, mask,input_ids2, mask2, image_inputs]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()    \n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_text:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        ins=[input_ids, mask,input_ids2, mask2]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "        \n",
    "    elif tweet:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        ins=[input_ids, mask]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    \n",
    "    return history,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x26b3ebf3b20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x26b3ebf3b20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids2 (InputLayer)         [(None, 245)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask2 (InputLayer)    [(None, 245)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "images (InputLayer)             [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rob (Rob)                       (None, 1)            66294727    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "                                                                 input_ids2[0][0]                 \n",
      "                                                                 attention_mask2[0][0]            \n",
      "                                                                 images[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 66,294,727\n",
      "Trainable params: 269,799\n",
      "Non-trainable params: 66,024,928\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "163/163 [==============================] - ETA: 0s - loss: 7.3098 - accuracy: 0.5644WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "163/163 [==============================] - 1313s 8s/step - loss: 7.2970 - accuracy: 0.5646 - val_loss: 1.4590 - val_accuracy: 0.6765\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 1179s 7s/step - loss: 1.2430 - accuracy: 0.6846 - val_loss: 1.2086 - val_accuracy: 0.6507\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 1185s 7s/step - loss: 1.1659 - accuracy: 0.6548 - val_loss: 1.1636 - val_accuracy: 0.7353\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 1183s 7s/step - loss: 1.1243 - accuracy: 0.6774 - val_loss: 0.9695 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 1183s 7s/step - loss: 1.0576 - accuracy: 0.6656 - val_loss: 1.0603 - val_accuracy: 0.6360\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 1171s 7s/step - loss: 1.0146 - accuracy: 0.6798 - val_loss: 1.0267 - val_accuracy: 0.7463\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 1211s 7s/step - loss: 1.0560 - accuracy: 0.6741 - val_loss: 0.9838 - val_accuracy: 0.7169\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 1234s 8s/step - loss: 0.9402 - accuracy: 0.7371 - val_loss: 0.9035 - val_accuracy: 0.7059\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 1232s 8s/step - loss: 0.8545 - accuracy: 0.7325 - val_loss: 0.8284 - val_accuracy: 0.7426\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 1228s 8s/step - loss: 0.8317 - accuracy: 0.7153 - val_loss: 0.9525 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model=run_model(tweet=False,img=False,tweet_text=False,tweet_txt_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=plt.plot(model[0].history['accuracy'],linestyle='-', marker='s', color='r')\n",
    "y=plt.plot(model[0].history['val_accuracy'],linestyle='-', marker='s', color='b')\n",
    "def plot(train,test):\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.xlim(1, 10)\n",
    "    plt.ylim(0.1,1 )\n",
    "    plt.grid()\n",
    "    return plt.show()\n",
    "plot(x,y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "z=model[1].predict(test)\n",
    "ypred=np.where(z<=0.49,0,1)\n",
    "ytest=[k for i,j in test for k in j.numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion_mat(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    labels = [\"Negative\",\"Positive\"]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "    disp.plot(cmap=plt.cm.Blues,values_format='d')\n",
    "    return plt.show()\n",
    "\n",
    "confusion_mat(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8672566371681416\n",
      "Recall: 0.658\n",
      "Accuracy: 0.757\n",
      "F1 Score: 0.748\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {}\".format(precision_score(ytest, ypred)))\n",
    "print('Recall: %.3f' % recall_score(ytest, ypred))\n",
    "print('Accuracy: %.3f' % accuracy_score(ytest, ypred))\n",
    "print('F1 Score: %.3f' % f1_score(ytest, ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.88      0.77       123\n",
      "    Positive       0.87      0.66      0.75       149\n",
      "\n",
      "    accuracy                           0.76       272\n",
      "   macro avg       0.77      0.77      0.76       272\n",
      "weighted avg       0.78      0.76      0.76       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print(classification_report(ytest, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UWAMAH~1\\AppData\\Local\\Temp/ipykernel_60468/758176997.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_1['Pred Target']=ypred\n"
     ]
    }
   ],
   "source": [
    "ypred=ypred.flatten()\n",
    "test_1['Pred Target']=ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.to_csv(\"Predicted+Tweet+Text+Img+Albert+Inception.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
