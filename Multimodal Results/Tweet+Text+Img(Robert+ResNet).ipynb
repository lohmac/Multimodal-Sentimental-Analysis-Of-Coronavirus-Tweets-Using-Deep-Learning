{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Importing of Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFBertModel, logging\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "bert = TFRobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "dat = pd.read_csv('C:\\\\Users\\\\UWAMAHIRWE\\\\Desktop\\\\Thesis\\\\crypto_data\\\\fin_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation Of Data Pipelines\n",
    "#https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "\n",
    "\n",
    "class preparation():\n",
    "    def __init__(self,df,tokenizer,bert,max_len_tweet,max_len_text_data,tweet=True,tweet_text=True,image=True):\n",
    "        self.df=df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert = bert\n",
    "        self.max_len_tweet=max_len_tweet\n",
    "        self.max_len_text_data=max_len_text_data\n",
    "        self.tweet=tweet\n",
    "        self.tweet_text=tweet_text\n",
    "        self.image=image\n",
    "        self.tokenizer=tokenizer\n",
    "        self.bert=bert\n",
    "        \n",
    "        \n",
    "        \n",
    "    def tokenize(self,sentences,max_len):\n",
    "        \n",
    "        input_ids=[]\n",
    "        attention_masks=[]\n",
    "        for sent in sentences:\n",
    "            bert_inp=self.tokenizer.encode_plus(sent,max_length=max_len,add_special_tokens = True,pad_to_max_length = True,return_attention_mask = True,truncation = True)\n",
    "            input_ids.append(bert_inp['input_ids'])\n",
    "            attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "        input_ids=np.asarray(input_ids)\n",
    "        attention_masks=np.array(attention_masks)\n",
    "        return input_ids,attention_masks\n",
    "    \n",
    "    \n",
    "    def prep_txt(self,input_ids, masks, input_ids2, masks2, path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2,'images': image}, labels\n",
    "\n",
    "\n",
    "    def prep_image(self,path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'images1': image}, labels\n",
    "\n",
    "    def prep_tweet(self,input_ids, masks, labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "    \n",
    "    def prep_txt_imtxt_image(self,input_ids, masks, input_ids2, masks2,labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2}, labels\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def prep_data_pipeline(self):\n",
    "        sentences=self.df['tweet']\n",
    "        sentences1=self.df['text_data']\n",
    "        input_ids,attention_masks=self.tokenize(sentences,self.max_len_tweet)\n",
    "        input_ids1,attention_masks1=self.tokenize(sentences1,self.max_len_text_data)\n",
    "        paths =[img for i,img in enumerate(self.df['Path'])]\n",
    "        labels=self.df['Target'].to_numpy()#.reshape((-1,1))\n",
    "        if self.tweet:\n",
    "            if self.tweet_text:\n",
    "                if self.image:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,paths,labels)).map(self.prep_txt).batch(5)\n",
    "                    \n",
    "                else:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,labels)).map(self.prep_txt_imtxt_image).batch(5)\n",
    "                    \n",
    "            \n",
    "            elif self.tweet_text==False:\n",
    "                if self.image==False:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks,labels)).map(self.prep_tweet).batch(5)\n",
    "                    \n",
    "                \n",
    "                \n",
    "        elif self.tweet==False:\n",
    "            if self.tweet_text==False:\n",
    "                if self.image:\n",
    "                    dataset=tf.data.Dataset.from_tensor_slices((paths,labels)).map(self.prep_image).batch(5)\n",
    "                        \n",
    "                    \n",
    "        return dataset    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1,test_1=train_test_split(dat, test_size=.25, random_state=42)\n",
    "train=preparation(df=train_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=True,image=True).prep_data_pipeline()\n",
    "test=preparation(df=test_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=True,image=True).prep_data_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.BatchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.Dense1 = tf.keras.layers.Dense(115, activation='relu', kernel_regularizer=l2(0.01))\n",
    "        self.Dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.Dense2 = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.BatchNormalization(inputs)\n",
    "        x = self.Dense1(x)\n",
    "        x = self.Dropout(x)\n",
    "        x = self.Dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rob(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Rob, self).__init__()\n",
    "        self.GlobalMaxPool1D = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.GlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.ResNet=tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(200,200,3), pooling=False, classes=2)\n",
    "        self.bert= TFRobertaModel.from_pretrained('roberta-base')\n",
    "        self.block = MLPBlock()\n",
    "        #self.Flat=tf.keras.layers.Flatten()\n",
    "        self.ResNet.trainable=False\n",
    "        self.bert.trainable=False\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_ids_c = tf.keras.layers.concatenate([inputs[0],inputs[2]])\n",
    "        mask_c =  tf.keras.layers.concatenate([inputs[1],inputs[3]])\n",
    "        text_embeddings = bert(input_ids_c, attention_mask=mask_c)[0]   #We take the first value from tuple which is the pooled_output\n",
    "        text_feat = self.GlobalMaxPool1D(text_embeddings)\n",
    "        image_embeddings = self.ResNet(inputs[4])\n",
    "        #self.Flat=tf.keras.layers.Flatten() Can use GlobalAveragePooling2D or Flatten but when used Flatten caused overfitting issues\n",
    "        #https://stackoverflow.com/questions/49295311/what-is-the-difference-between-flatten-and-globalaveragepooling2d-in-keras#:~:text=Flatten%20accepts%20as%20input%20tensor,H*W*n_channels)%20.&text=GlobalAveragePooling2D%20accepts%20as%20input%204D%20tensor.\n",
    "        image_feat = self.GlobalAveragePooling2D(image_embeddings)\n",
    "        x = tf.keras.layers.concatenate([text_feat, image_feat]) #Combining text and image vectors(FUSION) into a single vector\n",
    "        x =self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(tweet,img,tweet_text,tweet_txt_img):\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    checkpoint_filepath = r'C:\\\\Users\\\\UWAMAHIRWE\\\\Desktop\\\\Thesis\\\\crypto_data\\\\model_wt_full_robert_res.ckpt'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "    early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, verbose=1)\n",
    "    seq_len=250\n",
    "    seq_len2=245\n",
    "    if img:\n",
    "        ins = tf.keras.layers.Input(shape=(200, 200, 3),name='images1')\n",
    "        outs = Images()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_txt_img:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        image_inputs=tf.keras.layers.Input(shape=(200,200,3),name=\"images\")\n",
    "        ins=[input_ids, mask,input_ids2, mask2, image_inputs]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()    \n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_text:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        ins=[input_ids, mask,input_ids2, mask2]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "        \n",
    "    elif tweet:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        ins=[input_ids, mask]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    \n",
    "    return history,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x260bcdb3a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x260bcdb3a60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids2 (InputLayer)         [(None, 245)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask2 (InputLayer)    [(None, 245)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "images (InputLayer)             [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rob (Rob)                       (None, 1)            148545767   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "                                                                 input_ids2[0][0]                 \n",
      "                                                                 attention_mask2[0][0]            \n",
      "                                                                 images[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 148,545,767\n",
      "Trainable params: 329,703\n",
      "Non-trainable params: 148,216,064\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "163/163 [==============================] - ETA: 0s - loss: 6.8219 - accuracy: 0.5541WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "163/163 [==============================] - 1150s 7s/step - loss: 6.8115 - accuracy: 0.5545 - val_loss: 1.8564 - val_accuracy: 0.6103\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 1072s 7s/step - loss: 1.5466 - accuracy: 0.7149 - val_loss: 1.4272 - val_accuracy: 0.6066\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 1068s 7s/step - loss: 1.3572 - accuracy: 0.6684 - val_loss: 1.4525 - val_accuracy: 0.5919\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 1078s 7s/step - loss: 1.4675 - accuracy: 0.6461 - val_loss: 1.8583 - val_accuracy: 0.5809\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 1063s 7s/step - loss: 1.6275 - accuracy: 0.6619 - val_loss: 1.7273 - val_accuracy: 0.6066\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "model=run_model(tweet=False,img=False,tweet_text=False,tweet_txt_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=plt.plot(model[0].history['accuracy'],linestyle='-', marker='s', color='r')\n",
    "y=plt.plot(model[0].history['val_accuracy'],linestyle='-', marker='s', color='b')\n",
    "def plot(train,test):\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.xlim(1, 10)\n",
    "    plt.ylim(0.1,1 )\n",
    "    plt.grid()\n",
    "    return plt.show()\n",
    "plot(x,y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "z=model[1].predict(test)\n",
    "ypred=np.where(z<=0.49,0,1)\n",
    "ytest=[k for i,j in test for k in j.numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion_mat(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    labels = [\"Negative\",\"Positive\"]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "    disp.plot(cmap=plt.cm.Blues,values_format='d')\n",
    "    return plt.show()\n",
    "\n",
    "confusion_mat(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6776859504132231\n",
      "Recall: 0.550\n",
      "Accuracy: 0.610\n",
      "F1 Score: 0.607\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {}\".format(precision_score(ytest, ypred)))\n",
    "print('Recall: %.3f' % recall_score(ytest, ypred))\n",
    "print('Accuracy: %.3f' % accuracy_score(ytest, ypred))\n",
    "print('F1 Score: %.3f' % f1_score(ytest, ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.56      0.68      0.61       123\n",
      "    Positive       0.68      0.55      0.61       149\n",
      "\n",
      "    accuracy                           0.61       272\n",
      "   macro avg       0.62      0.62      0.61       272\n",
      "weighted avg       0.62      0.61      0.61       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print(classification_report(ytest, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UWAMAH~1\\AppData\\Local\\Temp/ipykernel_46024/758176997.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_1['Pred Target']=ypred\n"
     ]
    }
   ],
   "source": [
    "ypred=ypred.flatten()\n",
    "test_1['Pred Target']=ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.to_csv(\"Predicted_Tweet_Text_Img_Robert_ResNet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
