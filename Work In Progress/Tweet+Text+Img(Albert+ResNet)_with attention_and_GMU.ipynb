{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Dataset\n",
    "dat = pd.read_csv('fin_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Importing of Packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFBertModel, logging\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "bert = TFAlbertModel.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation Of Data Pipelines\n",
    "#https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "\n",
    "class preparation():\n",
    "    def __init__(self,df,tokenizer,bert,max_len_tweet,max_len_text_data,tweet=True,tweet_text=True,image=True):\n",
    "        self.df=df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert = bert\n",
    "        self.max_len_tweet=max_len_tweet\n",
    "        self.max_len_text_data=max_len_text_data\n",
    "        self.tweet=tweet\n",
    "        self.tweet_text=tweet_text\n",
    "        self.image=image\n",
    "        self.tokenizer=tokenizer\n",
    "        self.bert=bert\n",
    "        \n",
    "        \n",
    "        \n",
    "    def tokenize(self,sentences,max_len):\n",
    "        \n",
    "        input_ids=[]\n",
    "        attention_masks=[]\n",
    "        for sent in sentences:\n",
    "            bert_inp=self.tokenizer.encode_plus(sent,max_length=max_len,add_special_tokens = True,pad_to_max_length = True,return_attention_mask = True,truncation = True)\n",
    "            input_ids.append(bert_inp['input_ids'])\n",
    "            attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "        input_ids=np.asarray(input_ids)\n",
    "        attention_masks=np.array(attention_masks)\n",
    "        return input_ids,attention_masks\n",
    "    \n",
    "    \n",
    "    def prep_txt(self,input_ids, masks, input_ids2, masks2, path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2,'images': image}, labels\n",
    "\n",
    "\n",
    "    def prep_image(self,path, labels):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.io.decode_image(image, channels=3,expand_animations = False)\n",
    "        image = tf.cast(image, tf.float32) / 255.0 \n",
    "        image = tf.image.resize(image, size=(200, 200)) \n",
    "        return {'images1': image}, labels\n",
    "\n",
    "    def prep_tweet(self,input_ids, masks, labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "    \n",
    "    def prep_txt_imtxt_image(self,input_ids, masks, input_ids2, masks2,labels):\n",
    "        return {'input_ids': input_ids, 'attention_mask': masks, \n",
    "            'input_ids2': input_ids2, 'attention_mask2': masks2}, labels\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def prep_data_pipeline(self):\n",
    "        sentences=self.df['tweet']\n",
    "        sentences1=self.df['text_data']\n",
    "        input_ids,attention_masks=self.tokenize(sentences,self.max_len_tweet)\n",
    "        input_ids1,attention_masks1=self.tokenize(sentences1,self.max_len_text_data)\n",
    "        paths =[img for i,img in enumerate(self.df['Path'])]\n",
    "        labels=self.df['Target'].to_numpy()#.reshape((-1,1))\n",
    "        if self.tweet:\n",
    "            if self.tweet_text:\n",
    "                if self.image:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,paths,labels)).map(self.prep_txt).batch(5)\n",
    "                    \n",
    "                else:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks, input_ids1, attention_masks1,labels)).map(self.prep_txt_imtxt_image).batch(5)\n",
    "                    \n",
    "            \n",
    "            elif self.tweet_text==False:\n",
    "                if self.image==False:\n",
    "                    dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_masks,labels)).map(self.prep_tweet).batch(5)\n",
    "                    \n",
    "                \n",
    "                \n",
    "        elif self.tweet==False:\n",
    "            if self.tweet_text==False:\n",
    "                if self.image:\n",
    "                    dataset=tf.data.Dataset.from_tensor_slices((paths,labels)).map(self.prep_image).batch(5)\n",
    "                        \n",
    "                    \n",
    "        return dataset     \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lohith\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_1,test_1=train_test_split(dat, test_size=.25, random_state=42)\n",
    "train=preparation(df=train_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=True,image=True).prep_data_pipeline()\n",
    "test=preparation(df=test_1,tokenizer=tokenizer,bert=bert,max_len_tweet=250,max_len_text_data=245,tweet=True,tweet_text=True,image=True).prep_data_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        query=inputs\n",
    "        key,val=tf.transpose(inputs),tf.transpose(inputs)\n",
    "        dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  \n",
    "        scaled_attention_logits =tf.matmul(query,key)/tf.math.sqrt(dk)\n",
    "        attention_weights =tf.keras.activations.softmax(scaled_attention_logits ,axis=1)\n",
    "        \n",
    "        out=tf.transpose(tf.matmul(val,attention_weights))\n",
    "       \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.BatchNormalization = tf.keras.layers.BatchNormalization()\n",
    "        self.Dense1 = tf.keras.layers.Dense(115, activation='relu', kernel_regularizer=l2(0.01))\n",
    "        self.Dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.Dense2 = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.BatchNormalization(inputs)\n",
    "        x = self.Dense1(x)\n",
    "        x = self.Dropout(x)\n",
    "        x = self.Dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMU(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GMU, self).__init__()\n",
    "        self.Dense1 = tf.keras.layers.Dense(512, activation='tanh', kernel_regularizer=l2(0.01))\n",
    "        self.Dense2 = tf.keras.layers.Dense(512, activation='tanh', kernel_regularizer=l2(0.01))\n",
    "        self.z = tf.keras.layers.Dense(512, activation='sigmoid', kernel_regularizer=l2(0.01))\n",
    "         \n",
    "    def call(self, inputs):\n",
    "        img = self.Dense1(inputs[0])\n",
    "        txt = self.Dense2(inputs[1])\n",
    "        concat =tf.keras.layers.concatenate([inputs[0],inputs[0]])\n",
    "        z    =  self.z(concat)\n",
    "        hv= tf.keras.layers.multiply([img,z])\n",
    "        lam= tf.keras.layers.Lambda(lambda x: 1.-x)(z)\n",
    "        ht=tf.keras.layers.multiply([lam,txt])\n",
    "        h=tf.keras.layers.Add()([hv,ht])\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rob(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Rob, self).__init__()\n",
    "        self.GlobalMaxPool1D = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.GlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.ResNet=tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(200,200,3), pooling=False, classes=2)\n",
    "        self.bert=TFAlbertModel.from_pretrained('albert-base-v2')\n",
    "        #self.Flat=tf.keras.layers.Flatten()\n",
    "        self.block = MLPBlock()\n",
    "        self.GMU= GMU()\n",
    "        self.Attention = Attention()\n",
    "        self.ResNet.trainable=False\n",
    "        self.bert.trainable=False\n",
    "        \n",
    "    def call(self, inputs,Attention=False):\n",
    "        input_ids_c = tf.keras.layers.concatenate([inputs[0],inputs[2]])\n",
    "        mask_c =  tf.keras.layers.concatenate([inputs[1],inputs[3]])\n",
    "        text_embeddings = bert(input_ids_c, attention_mask=mask_c)[0]  #We take the first value from tuple which is the pooled_output which is the embedding hence [0]\n",
    "        text_feat = self.GlobalMaxPool1D(text_embeddings)\n",
    "        image_embeddings = self.ResNet(inputs[4])\n",
    "        #self.Flat=tf.keras.layers.Flatten() Can use GlobalAveragePooling2D or Flatten but when used Flatten caused overfitting issues\n",
    "        #https://stackoverflow.com/questions/49295311/what-is-the-difference-between-flatten-and-globalaveragepooling2d-in-keras#:~:text=Flatten%20accepts%20as%20input%20tensor,H*W*n_channels)%20.&text=GlobalAveragePooling2D%20accepts%20as%20input%204D%20tensor.\n",
    "        \n",
    "        \n",
    "        image_feat = self.GlobalAveragePooling2D(image_embeddings)\n",
    "        #x = tf.keras.layers.concatenate([text_feat, image_feat])#Combining text and image vectors(FUSION) into a single vector\n",
    "        gm= self.GMU([image_feat,text_feat])\n",
    "        if Attention: #Applying Attention mechanism to the fused vector\n",
    "            x = self.Attention(gm)\n",
    "            x = self.block(x)\n",
    "        else:\n",
    "            x = self.block(gm)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention NO\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 250)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 250)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids2 (InputLayer)        [(None, 245)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask2 (InputLayer)   [(None, 245)]        0           []                               \n",
      "                                                                                                  \n",
      " images (InputLayer)            [(None, 200, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rob_5 (Rob)                    (None, 1)            38850023    ['input_ids[0][0]',              \n",
      "                                                                  'attention_mask[0][0]',         \n",
      "                                                                  'input_ids2[0][0]',             \n",
      "                                                                  'attention_mask2[0][0]',        \n",
      "                                                                  'images[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,850,023\n",
      "Trainable params: 3,600,615\n",
      "Non-trainable params: 35,249,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_len=250\n",
    "optimizer= tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "seq_len2=245\n",
    "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "image_inputs=tf.keras.layers.Input(shape=(200,200,3),name=\"images\")\n",
    "ins=[input_ids, mask,input_ids2, mask2, image_inputs]\n",
    "outs = Rob()(ins)\n",
    "model = tf.keras.Model(ins, outs)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "model.summary()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(tweet,img,tweet_text,tweet_txt_img):\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    checkpoint_filepath = r'C:\\Users\\UWAMAHIRWE\\Desktop\\Thesis\\crypto_data\\model_wt_full_albert_res.ckpt'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "    early_stop=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=4, verbose=1)\n",
    "    seq_len=250\n",
    "    seq_len2=245\n",
    "    if img:\n",
    "        ins = tf.keras.layers.Input(shape=(200, 200, 3),name='images1')\n",
    "        outs = Images()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.summary()\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_txt_img:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        image_inputs=tf.keras.layers.Input(shape=(200,200,3),name=\"images\")\n",
    "        ins=[input_ids, mask,input_ids2, mask2, image_inputs]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()    \n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    elif tweet_text:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        input_ids2 = tf.keras.layers.Input(shape=(seq_len2,), name='input_ids2', dtype='int32')\n",
    "        mask2 = tf.keras.layers.Input(shape=(seq_len2,), name='attention_mask2', dtype='int32')\n",
    "        ins=[input_ids, mask,input_ids2, mask2]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "        \n",
    "    elif tweet:\n",
    "        input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "        mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "        ins=[input_ids, mask]\n",
    "        outs = Rob()(ins)\n",
    "        model = tf.keras.Model(ins, outs)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        history=model.fit(train,validation_data=test, epochs=10,callbacks=[model_checkpoint_callback,early_stop])\n",
    "    \n",
    "    return history,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=run_model(tweet=False,img=False,tweet_text=False,tweet_txt_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=plt.plot(model[0].history['accuracy'],linestyle='-', marker='s', color='r')\n",
    "y=plt.plot(model[0].history['val_accuracy'],linestyle='-', marker='s', color='b')\n",
    "def plot(train,test):\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.xlim(1, 10)\n",
    "    plt.ylim(0.1,1 )\n",
    "    plt.grid()\n",
    "    return plt.show()\n",
    "plot(x,y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=model[1].predict(test)\n",
    "ypred=np.where(z<=0.49,0,1)\n",
    "ytest=[k for i,j in test for k in j.numpy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    labels = [\"Negative\",\"Positive\"]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "    disp.plot(cmap=plt.cm.Blues,values_format='d')\n",
    "    return plt.show()\n",
    "\n",
    "confusion_mat(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: {}\".format(precision_score(ytest, ypred)))\n",
    "print('Recall: %.3f' % recall_score(ytest, ypred))\n",
    "print('Accuracy: %.3f' % accuracy_score(ytest, ypred))\n",
    "print('F1 Score: %.3f' % f1_score(ytest, ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print(classification_report(ytest, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=ypred.flatten()\n",
    "test_1['Pred Target']=ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.to_csv(\"Predicted Tweet+Text+Img Albert+ResNet.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
